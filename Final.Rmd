---
title: "Final"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(dplyr)
library(tidyr)
library(magrittr)
library(stringr)
library(readr)
library(tidyverse)
```

```{r 0}
url <- "https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop?ajax=yw1&page=1"

value_tab <- url %>%
  read_html() %>%
  html_node(".items") %>%
  html_table(fill = TRUE) %>%
  set_colnames(c("ID","Name/Pos","??","Name","Position","Age","???","????","Value")) %>%
  as_data_frame()

for(i in seq(2, 20)) {
  url <- paste("https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop?ajax=yw1&page=", i, sep = "")
  tab <- url %>%
  read_html() %>%
  html_node(".items") %>%
  html_table(fill = TRUE) %>%
  set_colnames(c("ID","Name/Pos","??","Name","Position","Age","???","????","Value")) %>%
  as_data_frame()

  value_tab <- rbind(value_tab, tab)
}

head(value_tab)
```

```{r 1}
value_tab <- value_tab %>%
  filter(is.na(ID) == FALSE) %>%
  select(Name, Position, Age, Value)

value_tab$Value <- gsub("([0-9]+),([0-9]{2}) Mill. \200", "\\1\\20000", value_tab$Value)
value_tab$Value <- as.numeric(value_tab$Value)

value_tab$Name[value_tab$Name == "Saúl Ñíguez"] <- "Saúl"
value_tab$Name <- gsub("([A-Z])\\S+ (.+)", "\\1. \\2", value_tab$Name)
value_tab$Name[value_tab$Name == "P. Coutinho"] <- "Coutinho"

head(value_tab)
```

```{r 2}
fifa_tab <- read.csv("data.csv", encoding = "UTF-8") %>%
  slice(0:1000)

fifa_tab$Name <- gsub("([A-Z])\\S+ (.+)", "\\1. \\2", fifa_tab$Name)
fifa_tab$Name[fifa_tab$Name == "N. Jr"] <- "Neymar"
fifa_tab$Name[fifa_tab$Name == "D. Gea"] <- "D. de Gea"
fifa_tab$Name[fifa_tab$Name == "K. D. Bruyne"] <- "K. De Bruyne"

fifa_tab %>%
  select(Name, Age, Overall, Position) %>%
  head()
```

```{r}
tab <- fifa_tab %>%
  inner_join(value_tab, by = "Name")

tab <- tab %>%
  select(Name, Age.y, Value.y, Position.x, Overall) %>%
  rename(Age = "Age.y", Value = "Value.y", Position = "Position.x")

head(tab)
```

Now we have a table that we can work with. The table is tidy with no missing data, and we have all of the information we need to begin our investigation. Our investigation will make heavy use of the linear regression technique. Linear regression revolves around attempting to minimize the residual sum of squares (RSS) of the data. RSS is the squared distance of each input from the linear regression line. In fact, linear regression is the line that minimizes the residual sum of squares if done perfectly. Much more detail can be given, but this should be a solid basis to understand the following analysis. More reading about the history and importance of linear regression can be found here: http://people.duke.edu/~rnau/regintro.htm.

We being with our original assumption that the value of a player is heavily reliant on their overall ability and their age. As such, we can regress value on a player's age and overall rating to see if this assumption holds. Before we perform the regression, let's first see if we can intuitively see a linear relationship by plotting the data:

```{r}
tab %>%
  ggplot(mapping = aes(x = Overall, y = Value, color = Age)) +
  geom_point() + 
  labs(title = "Players' Values, Overall Ratings, and Ages")
```

This is a scatter plot of our data, where the y position is a player's value, the x position is a player's overall rating, and the color is a player's age. The darker colors represent younger players. The code should be self-explanatory; we map variables to certain characteristics and choose the geometric representation by using geom_point.

Intuitively, there does seem to be a relationship between value and overall, as well as value and age. As overall increases, value also looks to increase. Also, the dots appear to get darker as you go higher. However, something does seem concerning. The relationship is not convincingly linear; it appears it could be quadratic or even exponential. And, in fact, it is entirely possible that this relationship isn't linear. As such, we can transform the data to help with our investigation, without losing much interpretability. Watch what happens when we perform a logarithmic transformation to the value attribute:

```{r}
tab %>%
  ggplot(mapping = aes(x = Overall, y = log10(Value), color = Age)) +
  geom_point() + 
  labs(title = "Logarithmic Transformation of Value", y = "Logarithmic Value", x = "Overall")
```

Now the data seems to have a much more linear relationship, and we can still interpret this graph. By using log base 10, we can effectively interpret the y position as "How many zeroes are at the end of a check to purchase this player?" From here on, we'll use log base ten of value in our analysis. Finally, we can perform our first linear regression. Here, we will regress value on both overall rating and age.

```{r 3}
tab %>%
  ggplot(mapping = aes(x = Overall, y = log10(Value), color = Age)) +
  geom_point() + 
  geom_smooth(method = lm) + 
  labs(title = "Regressing Value on Overall Rating and Age", y = "Logarithmic Value", x = "Overall")
```

The geom_smooth line adds a line of best fit, and the method argument tells it to use linear regression. It seems our intuition was correct; there is a definite correlation between value and a player's age and their skill. However, this is still intuition. How do we know that this relationship isn't caused by randomness of the data? Can we quantitively define how much of a relationship there is in a linear model? It turns out there is a way, which uses something called the p-value of linear regression, seen below:

```{r}
tab %>%
  lm(formula = Value ~ Overall + Age) %>%
  broom::tidy() %>%
  select(term, estimate, p.value)
```

The two columns estimate and p.value are essential to understanding linear regression. First, the estimate of the Overall row is interpreted as: "Assuming every other attribute is held constant, if a player's Overall increases by 1, then the value of the player increases by ~7,000,000." Essentially, the estimate is the slope of the regression line assuming everything else is held constant. The p-value has a deeper meaning rooted in sampling and A/B testing, which can be read about more here: https://conductrics.com/pvalues. The general gist is this: first, assume that there is no correlation between the two attributes (that is, the estimate is 0, or the regression line is horizontal). Then, the p.value is the probability that there is a statistically significant difference from the assumption that there is no correlation. Generally, we say the difference is significant if the p-value is less than 0.05. 

In this case, there is a significant correlation for both overall and age. So, if we performed regression on each of these separately, we should still see a strong correlation and a linear fit to match. We begin with the overall statistic.

```{r 5}
tab %>%
  ggplot(mapping = aes(x = Overall, y = log10(Value))) +
  geom_point() +
  geom_smooth(method = lm) + 
  labs(title = "Regressing Value on Overall Rating", y = "Logarithmic Value", x = "Overall")
```

There's no surprises here. There is still a strong positive correlation between overall rating and value. 

```{r}
tab %>%
  lm(formula = Value ~ Overall) %>%
  broom::tidy() %>%
  select(term, estimate, p.value)
```

This is further proof of our claim. We can confidently say that overall rating has an impact on a player's value. Now, we move on to age.

```{r 4}
tab %>%
  ggplot(mapping = aes(x = Age, y = log10(Value))) +
  geom_point() +
  geom_smooth(method = lm) + 
  labs(title = "Regressing Value on Age", y = "Logarithmic Value", x = "Overall")
```

This is also somewhat expected; lower aged players tend to have higher values. But, this correlation is much less obvious than the previous one. Intuitively, it'd be difficult to see the negative correlation. 

```{r}
tab %>%
  lm(formula = Value ~ Age) %>%
  broom::tidy() %>%
  select(term, estimate, p.value)
```
In fact, this relationship isn't even statistically significant, since the p-value isn't less than 0.05. This is definitely concerning, since in the first example when we used overall and age as predictors, both had significant p-values. Why doesn't the same hold now? One way we can check what is going on is by looking at a plot of the residuals to see if there is some trend that is unseen in the original graphs. Ideally, the residuals would be spread uniformly about 0 and show no signs of a trend. Let's begin with the Value regressed on Overall, since we believe that is a good example of linear regression.

```{r}
log_tab <- tab
log_tab$Value <- sapply(log_tab$Value, log10)

log_tab %>%
  lm(formula = Value ~ Overall) %>%
  broom::augment() %>%
  inner_join(log_tab, by = "Value", "Overall") %>%
  ggplot(mapping = aes(x = Overall.y, y = .resid)) +
  geom_point() + 
  labs(title = "Plot of Residuals after Regression on Overall Rating", y = "Residuals", x = "Overall")
```

While not perfect, the residuals don't appear to increase or decrease as overall rating increases. Most estimates fall with +- 0.3 and there is a pretty even amount of data on both sides of 0. This graph is further evidence that a linear model is a good representation of the relationship between value and overall rating. Now, let's look at the same graph but replacing overall with age.

```{r}
log_tab %>%
  lm(formula = Value ~ Age) %>%
  broom::augment() %>%
  inner_join(log_tab, by = "Value", "Age") %>%
  ggplot(mapping = aes(x = Age.y, y = .resid)) +
  geom_point() + 
  labs(title = "Plot of Residuals after Regression on Age", y = "Residuals", x = "Age")
```

Notice now that the residuals are much larger above 0, and there seems to be a relationship between age and residual. Residual seems to peak when age is about 26 then starts to decline as you move away from 26. As such, this is evidence that there is not an obvious linear relationship between value and age. 

The obvious question is why was there a significant relationship for age only when it was included in a regression with overall rating? It turns out our problem is a common one within linear regression. The problem of _collinearity_ is caused when attempting to regress using two variables that have a linear relationship. More info here: https://www.statisticshowto.datasciencecentral.com/multicollinearity/. I'll demonstrate now that a player's overall rating is actually dependent on age.

```{r}
tab %>%
  ggplot(mapping = aes(x = Age, y = Overall)) +
  geom_point() +
  geom_smooth(method = lm) + 
  labs(title = "Collinearity of Overall Rating and Age", x = "Age", y = "Overall")
```

Intuitively, there is a clear correlation between age and rating.

```{r}
tab %>%
  lm(formula = Overall ~ Age) %>%
  broom::tidy() %>%
  select(term, estimate, p.value)
```

The p-value shows the correlation is significant. Thus, age plays a role in how a player's overall rating is calculated by the makers of FIFA. The problem of collinearity is still mostly unsolved in terms of how to avoid it. In general, the best solution is to avoid regressing using two predictor variables that have a linear relationship. As such, we should not be using age as a predictor, and the best model we have so far is the one using only overall rating as the predictor of value.

Finally, I will investigate if a player's position impacts their value. First, I will divide the players into four types: forwards, midfielders, backs, and goalkeepers. To do this I will use the position FIFA assigns to each player. A forward will be one of: ST (striker), L/RW (left/right wing), or L/C/RF (left/center/right forward). Midfielders will be anything ending in M, while backs will end in B. Finally, goalkeepers must be GK.

```{r}
tab$Position <- sapply(tab$Position, as.character)

tab <- tab %>%
  mutate(Type = NA) 

for(i in seq(1, nrow(tab))) {
  if(endsWith(tab$Position[i], "M")) { 
    tab$Type[i] <- "M"  
  }
  else if(endsWith(tab$Position[i], "B")) {
    tab$Type[i] <- "B"
  }
  else if(tab$Position[i] == "GK") {
    tab$Type[i] <- "G"
  }
  else {
    tab$Type[i] <- "F"
  }
}

tab %>%
  slice(1:10)
```

Now that we've divided players into their types, let's see how our current model works based on these different positions.

```{r}
log_tab <- tab

log_tab$Value <- sapply(log_tab$Value, log10)

log_tab %>%
  lm(formula = Value ~ Overall) %>%
  broom::augment() %>%
  inner_join(log_tab, by = "Value", "Overall") %>%
  ggplot(mapping = aes(x = Type, y = .resid)) + 
  geom_boxplot() + 
  labs(title = "Residuals of Regressing Value on Overall by Type of Player", x = "Type", y = "Residual")

```

From this boxplot, there does not seem to be a huge difference between positions. But, we can still attempt a linear regression and see.

```{r}
log_tab %>%
  ggplot(mapping = aes(x = Overall, y = Value, color = Type)) +
  geom_smooth(method = lm) + 
  geom_point() + 
  labs(title = "Regressing Value on Overall and Different Player Types", x = "Overall", y = "Logarithmic Value")
```

Perhaps surprisingly, we see that the slope of the regression line for backs is lower than that of the other three types. We can look at the p-values to see how significant this difference is.

```{r}
log_tab$Type <- factor(log_tab$Type, ordered = FALSE)
log_tab$Type <- relevel(log_tab$Type, ref = 1)

log_tab %>%
  lm(formula = Value ~ Overall * Type) %>%
  broom::tidy() %>%
  slice(-(3:5)) %>%
  select(term, estimate, p.value)
```

This table is confusing to interpret, mostly because it appears that only three of the four types of players are represented. What is actually happening is that each type does get its own term in the regression line and estimate, except that one of them is used as the "default" line. The first two lines of code make it so that the back type is the default, meaning the "Overall" row is really "Overall:TypeB". As such, we can see how different the other three types are from backs. From here we can glean that both forwards and midfielders are statistically significantly different from backs, while goalkeepers are not. Thus, it would make sense to at least split the players into two groups, forwards/midfielders and backs/goalkeepers, and perform regression.

```{r}
tab <- tab %>%
  mutate(FM = ifelse(Type == "F" | Type == "M", "F/M", "B/G"))

tab %>%
  ggplot(mapping = aes(x = Overall, y = Value)) + 
  facet_grid(cols = vars(FM)) + 
  geom_point() + 
  geom_smooth(method = lm) + 
  labs(title = "Regression Faceted Into Two Groups of Players", x = "Overall", y = "Value")

```

When faceting the difference is made much clearer. Playing as a forward or midfielder definitely seems to increase your value more than if you are a back or goalkeeper. We can continue further and facet over all four positions.

```{r}
tab %>%
  ggplot(mapping = aes(x = Overall, y = Value)) + 
  facet_grid(cols = vars(Type)) + 
  geom_point() + 
  geom_smooth(method = lm) +
  labs(title = "Regression Faceted Into Two Groups of Players", x = "Overall", y = "Value")
```

We can see that there is some variation between all four types of players. At this point we have a smaller sample size for each group, especially goalkeepers, so it is difficult to generalize these findings. At the very least, there is some evidence that a player's position also affects their value. In particular, the further up the field they play, the more money they are worth.